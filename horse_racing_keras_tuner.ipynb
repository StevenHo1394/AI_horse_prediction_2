{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4537b284",
   "metadata": {},
   "source": [
    "# Horse Racing Prediction by Deep Learning\n",
    "\n",
    "This AI Horse racing prediction is using a 3-layer Neural Network to predict the finishing position of each horse in a race. The data used to train this model is obtained from the Hong Kong Jockey Club (HKJC). The model is built and trained by Tensorflow. Supervised learning is used in this project to classify the expected finishing position of the horses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076e85e",
   "metadata": {},
   "source": [
    "<H2> Part 1: Data Input and Preprocessing </H2>\n",
    "\n",
    "In this part of the program, we will import the data obtained from the HKJC. First of all, the following features were selected based on my past horse picking experience, namely:\n",
    "\n",
    "- position: The starting position of the horse. If the position is \"1\", it indicates the closest position to the hurdle and should be benficial in non-straight race courses.\n",
    "\n",
    "- load: This is the loading of the horse in pounds. Maximum is 133.\n",
    "\n",
    "- ON odds: This is the overnight odds of the horse provided by the HKJC.\n",
    "\n",
    "- odds: This is the odds of the horse 15 min before the race.\n",
    "\n",
    "- class: This is the class of the case. It is common to all horses in a race except special races.\n",
    "\n",
    "- num horses: This is the number of horses participated in the race.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b418f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version = 2.5.0\n"
     ]
    }
   ],
   "source": [
    "#Loading the data and preprocessing it.\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print (\"tensorflow version = \" + str(tf.__version__))\n",
    "\n",
    "PATH_TRAINING_DATA = 'training_data/horse_data_train_test.csv'\n",
    "\n",
    "dataset = pd.read_csv(PATH_TRAINING_DATA)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0ba4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.02049028e-02  8.74118149e-01 -3.92285578e-01 -6.41413743e-01\n",
      "  -4.83257447e-01 -1.01059339e+00]\n",
      " [-5.76996545e-01 -5.70991947e-01 -7.36584641e-01 -8.59945648e-01\n",
      "  -4.83257447e-01 -1.01059339e+00]\n",
      " [ 6.89982560e-01 -9.65112882e-01 -5.24708294e-01 -6.70551330e-01\n",
      "  -4.83257447e-01 -1.01059339e+00]\n",
      " ...\n",
      " [-3.23600724e-01  1.00549179e+00 -5.57813973e-01 -3.50037868e-01\n",
      "   5.40893656e-01 -1.57559018e-01]\n",
      " [ 1.19677420e+00  6.11370859e-01 -6.12287864e-02 -3.86819342e-04\n",
      "   5.40893656e-01 -1.57559018e-01]\n",
      " [-1.59057983e+00  4.79997214e-01 -7.36584641e-01 -8.57031889e-01\n",
      "   5.40893656e-01 -1.57559018e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) #use \"fit_transform\" for training data\n",
    "X_test = sc.transform(X_test)       #use \"transform\" for testing data\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical((y_train-1), 14)\n",
    "y_test = tf.keras.utils.to_categorical((y_test-1), 14)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d7e03",
   "metadata": {},
   "source": [
    "<H2> Part 2: Building the Model </H2>\n",
    "\n",
    "We will construct a basic 3-layer model: one input layer, one output layer and one hidden layer.\n",
    "\n",
    "We will introduce Keras Tuner to find the best number of nuerons in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e93c74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "#create a new model\n",
    "def build_model(hp):\n",
    "\n",
    "    num_hidden_layers = hp.Choice('num_hidden_layers', values=[1, 2, 3])\n",
    "    num_units = hp.Choice('num_units', values=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5)\n",
    "    activation = hp.Choice('activation', values=['sigmoid', 'relu'])    \n",
    "        \n",
    "    # Initializing the ANN\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Adding the input layer and the first layer\n",
    "    # We have six features now, and one bias term, so the input layer has a size of 6+1\n",
    "    model.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "    #model.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "\n",
    "    # Adding the input layer and the hidden layer\n",
    "    # We set the size of the hidden layer to be the mean of input and output later, i.e. 10\n",
    "    #model.add(tf.keras.layers.Dense(units=hp.Int('units',\n",
    "    #                                             min_value=3,\n",
    "    #                                             max_value=25, \n",
    "    #                                             step=1), \n",
    "    #                                activation='sigmoid')) \n",
    "    \n",
    "    for _ in range(0, num_hidden_layers):\n",
    "        #model.add(tf.keras.layers.Dense(num_units, activation='sigmoid'))\n",
    "        model.add(tf.keras.layers.Dense(num_units, activation=activation))\n",
    "        model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "    #model.add(tf.keras.layers.Dense(\n",
    "    #  hp.Choice('units', [8, 16, 32]),\n",
    "    #  activation='sigmoid'))\n",
    "\n",
    "    # Adding a drop out layer\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    # We have 14 outputs, so the output later has a size of 14\n",
    "    model.add(tf.keras.layers.Dense(units=14, activation='softmax'))\n",
    "\n",
    "    # Compiling the model\n",
    "    #opt = tf.keras.optimizers.Adam(learning_rate=0.03) \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142daef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project .\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n",
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_hidden_layers (Choice)\n",
      "{'default': 1, 'conditions': [], 'values': [1, 2, 3], 'ordered': True}\n",
      "num_units (Choice)\n",
      "{'default': 3, 'conditions': [], 'values': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'ordered': True}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': None, 'sampling': None}\n",
      "activation (Choice)\n",
      "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 20 #100\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde70ed",
   "metadata": {},
   "source": [
    "<H2> Part 3a: Using Keras Tuner to find the best number of layers and neurons </H2>\n",
    "\n",
    "In this section, we would invetigate the best number of neurons in our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1389b409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in X_train = 693\n",
      "rows in y_train = 693\n",
      "Training model...\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "num_units: 12\n",
      "dropout_rate: 0.10513604980689638\n",
      "activation: sigmoid\n",
      "Score: 0.2520325183868408\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "num_units: 6\n",
      "dropout_rate: 0.35276679031830505\n",
      "Score: 0.2520325183868408\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "num_units: 3\n",
      "dropout_rate: 0.17036843627853782\n",
      "Score: 0.2520325183868408\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "num_units: 14\n",
      "dropout_rate: 0.2666663831817352\n",
      "Score: 0.24390244483947754\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "num_units: 14\n",
      "dropout_rate: 0.3278931705437662\n",
      "Score: 0.24390244483947754\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "num_units: 14\n",
      "dropout_rate: 0.24541134234212325\n",
      "Score: 0.24390244483947754\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 1\n",
      "num_units: 10\n",
      "dropout_rate: 0.125532953112122\n",
      "Score: 0.23577235639095306\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "num_units: 13\n",
      "dropout_rate: 0.2087933949086263\n",
      "Score: 0.23577235639095306\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "num_units: 12\n",
      "dropout_rate: 0.3909964561474727\n",
      "Score: 0.22764228284358978\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "num_units: 13\n",
      "dropout_rate: 0.2612823357900895\n",
      "Score: 0.22764228284358978\n"
     ]
    }
   ],
   "source": [
    "#This is code cell 3a) that trains a model from scratch and then saves it. Please note that it takes hours to train!\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "print(\"rows in X_train = \" + str(X_train.shape[0]) )\n",
    "print(\"rows in y_train = \" + str(y_train.shape[0]) )\n",
    "\n",
    "print(\"Training model...\")\n",
    "tuner.search(X_train, y_train, epochs=5000, validation_data=(X_test, y_test))\n",
    "best_model = tuner.get_best_models()[0]\n",
    "\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30efba64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an `input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4080/4114626843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#This is not working somehow:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must provide an `input_shape` argument.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_graph_network_for_inferred_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide an `input_shape` argument."
     ]
    }
   ],
   "source": [
    "#This is not working somehow:\n",
    "best_model.build()\n",
    "best_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fca70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3bb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41e5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bafaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
