{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4537b284",
   "metadata": {},
   "source": [
    "# Horse Racing Prediction Hyper-parameters Tuning by Keras\n",
    "\n",
    "This Jupyter notebook is used to tune the hyper-parameters for the horse racing prediction model. The tuning will provide the best values of:\n",
    "\n",
    "- number of hidden layers\n",
    "- number of neurons in the hidden layers\n",
    "- activation function\n",
    "- drop out rate in the dropout layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076e85e",
   "metadata": {},
   "source": [
    "<H2> Part 1: Data Input and Preprocessing </H2>\n",
    "\n",
    "In this part of the program, we will import the data obtained from the HKJC. First of all, the following features were selected based on my past horse picking experience, namely:\n",
    "\n",
    "- position: The starting position of the horse. If the position is \"1\", it indicates the closest position to the hurdle and should be benficial in non-straight race courses.\n",
    "\n",
    "- load: This is the loading of the horse in pounds. Maximum is 133.\n",
    "\n",
    "- ON odds: This is the overnight odds of the horse provided by the HKJC.\n",
    "\n",
    "- odds: This is the odds of the horse 15 min before the race.\n",
    "\n",
    "- class: This is the class of the case. It is common to all horses in a race except special races.\n",
    "\n",
    "- num horses: This is the number of horses participated in the race.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b418f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version = 2.5.0\n"
     ]
    }
   ],
   "source": [
    "#Loading the data and preprocessing it.\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print (\"tensorflow version = \" + str(tf.__version__))\n",
    "\n",
    "PATH_TRAINING_DATA = 'training_data/horse_data_train_test.csv'\n",
    "\n",
    "dataset = pd.read_csv(PATH_TRAINING_DATA)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0ba4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06771695  0.89160737 -0.38687433 -0.63908619 -0.45749246 -1.03163272]\n",
      " [-0.57595046 -0.56040189 -0.73466068 -0.85907985 -0.45749246 -1.03163272]\n",
      " [ 0.69463333 -0.95640441 -0.52063831 -0.66841868 -0.45749246 -1.03163272]\n",
      " ...\n",
      " [-1.33830074 -1.2204061  -0.05246437 -0.08176894 -1.4736673   0.69097648]\n",
      " [ 0.69463333 -1.35240694 -0.08590537  0.79820568 -1.4736673   0.69097648]\n",
      " [-1.08418398 -1.48440778 -0.52063831 -0.70068442 -1.4736673   0.69097648]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) #use \"fit_transform\" for training data\n",
    "X_test = sc.transform(X_test)       #use \"transform\" for testing data\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical((y_train-1), 14)\n",
    "y_test = tf.keras.utils.to_categorical((y_test-1), 14)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d7e03",
   "metadata": {},
   "source": [
    "<H2> Part 2: Building the Model </H2>\n",
    "\n",
    "We will introduce Keras Tuner to find the best number of nuerons in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45b4d1",
   "metadata": {},
   "source": [
    "<H2> Part 2a: Clearing the cache</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6954ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "tmp_project_folder = \"untitled_project\" \n",
    "tmp_checkpoint_folder = \".ipynb_checkpoints\"\n",
    "\n",
    "# checking whether file exists or not\n",
    "if os.path.exists(tmp_project_folder):    \n",
    "    shutil.rmtree(tmp_project_folder)\n",
    "\n",
    "if os.path.exists(tmp_checkpoint_folder):        \n",
    "    shutil.rmtree(tmp_checkpoint_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8167b",
   "metadata": {},
   "source": [
    "<H2> Part 2b: Building the model </H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93c74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "#create a new model\n",
    "def build_model(hp):\n",
    "\n",
    "    num_hidden_layers = hp.Choice('num_hidden_layers', values=[2, 3, 4])                   #3 choices\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5)                  #? choices\n",
    "    #num_units = hp.Choice('num_units', values=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12])           #10 choices    \n",
    "        \n",
    "    # Initializing the ANN\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    # Adding the input layer and the first layer\n",
    "    # We have six features now, and one bias term, so the input layer has a size of 6+1\n",
    "    model.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "    \n",
    "    for i in range(0, num_hidden_layers):\n",
    "        activation = hp.Choice('activation', values=['sigmoid', 'relu', 'tanh'])           #3 choices\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),                    #10 choices\n",
    "                                                 min_value=3,\n",
    "                                                 max_value=12,        \n",
    "                                                 step=1),\n",
    "                                        activation=activation))\n",
    "    \n",
    "    # Adding a drop out layer\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # Adding the output layer\n",
    "    # We have 14 outputs, so the output later has a size of 14\n",
    "    model.add(tf.keras.layers.Dense(units=14, activation='softmax'))\n",
    "\n",
    "    # Compiling the model\n",
    "    #opt = tf.keras.optimizers.Adam(learning_rate=0.03) \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "142daef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "num_hidden_layers (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 4], 'ordered': True}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': None, 'sampling': None}\n",
      "activation (Choice)\n",
      "{'default': 'sigmoid', 'conditions': [], 'values': ['sigmoid', 'relu', 'tanh'], 'ordered': False}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 12, 'step': 1, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 12, 'step': 1, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = 'val_accuracy',\n",
    "    max_trials = 50 #180 #20 #100\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde70ed",
   "metadata": {},
   "source": [
    "<H2> Part 3a: Using Keras Tuner to find the best number of layers and neurons </H2>\n",
    "\n",
    "In this section, we would invetigate the best number of neurons in our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1389b409",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 57s]\n",
      "val_accuracy: 0.16201117634773254\n",
      "\n",
      "Best val_accuracy So Far: 0.18435753881931305\n",
      "Total elapsed time: 01h 09m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "results:\n",
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 4\n",
      "dropout_rate: 0.39438245342289924\n",
      "activation: tanh\n",
      "units_0: 7\n",
      "units_1: 9\n",
      "units_2: 11\n",
      "units_3: 4\n",
      "Score: 0.18435753881931305\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "dropout_rate: 0.4221952237820654\n",
      "activation: sigmoid\n",
      "units_0: 4\n",
      "units_1: 11\n",
      "units_2: 7\n",
      "units_3: 7\n",
      "Score: 0.17877094447612762\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 4\n",
      "dropout_rate: 0.29687287001423956\n",
      "activation: sigmoid\n",
      "units_0: 3\n",
      "units_1: 6\n",
      "units_2: 9\n",
      "units_3: 11\n",
      "Score: 0.16759777069091797\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 4\n",
      "dropout_rate: 0.1328106090509752\n",
      "activation: tanh\n",
      "units_0: 8\n",
      "units_1: 6\n",
      "units_2: 4\n",
      "units_3: 6\n",
      "Score: 0.16759777069091797\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 4\n",
      "dropout_rate: 0.4401714343841514\n",
      "activation: tanh\n",
      "units_0: 8\n",
      "units_1: 7\n",
      "units_2: 10\n",
      "units_3: 5\n",
      "Score: 0.16759777069091797\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "dropout_rate: 0.47814729534356704\n",
      "activation: tanh\n",
      "units_0: 9\n",
      "units_1: 7\n",
      "units_2: 8\n",
      "units_3: 8\n",
      "Score: 0.16201117634773254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "dropout_rate: 0.4915526538282924\n",
      "activation: sigmoid\n",
      "units_0: 10\n",
      "units_1: 10\n",
      "units_2: 8\n",
      "units_3: 10\n",
      "Score: 0.16201117634773254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "dropout_rate: 0.11847708521741579\n",
      "activation: relu\n",
      "units_0: 8\n",
      "units_1: 6\n",
      "units_2: 11\n",
      "units_3: 10\n",
      "Score: 0.16201117634773254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 4\n",
      "dropout_rate: 0.25854345060701356\n",
      "activation: sigmoid\n",
      "units_0: 10\n",
      "units_1: 9\n",
      "units_2: 9\n",
      "units_3: 9\n",
      "Score: 0.16201117634773254\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 4\n",
      "dropout_rate: 0.22013120567218852\n",
      "activation: tanh\n",
      "units_0: 9\n",
      "units_1: 9\n",
      "units_2: 10\n",
      "units_3: 7\n",
      "Score: 0.16201117634773254\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "print(\"rows in X_train = \" + str(X_train.shape[0]) )\n",
    "print(\"rows in y_train = \" + str(y_train.shape[0]) )\n",
    "\n",
    "print(\"Training model...\")\n",
    "tuner.search(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))\n",
    "\n",
    "print(\"results:\")\n",
    "best_model = tuner.get_best_models()[0]\n",
    "\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af41e5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.sequential.Sequential object at 0x000001EDEF295348>\n"
     ]
    }
   ],
   "source": [
    "#This is not working somehow:\n",
    "print(best_model)\n",
    "\n",
    "#best_model.build()\n",
    "#best_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614023eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
