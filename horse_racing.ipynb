{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4537b284",
   "metadata": {},
   "source": [
    "# Horse Racing Prediction by Deep Learning\n",
    "\n",
    "This AI Horse racing prediction is using a 3-layer Neural Network to predict the finishing position of each horse in a race. The data used to train this model is obtained from the Hong Kong Jockey Club (HKJC). The model is built and trained by Tensorflow. Supervised learning is used in this project to classify the expected finishing position of the horses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076e85e",
   "metadata": {},
   "source": [
    "<H2> Part 1: Data Input and Preprocessing </H2>\n",
    "\n",
    "In this part of the program, we will import the data obtained from the HKJC. First of all, the following features were selected based on my past horse picking experience, namely:\n",
    "\n",
    "- position: The starting position of the horse. If the position is \"1\", it indicates the closest position to the hurdle and should be benficial in non-straight race courses.\n",
    "\n",
    "- load: This is the loading of the horse in pounds. Maximum is 133.\n",
    "\n",
    "- ON odds: This is the overnight odds of the horse provided by the HKJC.\n",
    "\n",
    "- odds: This is the odds of the horse 15 min before the race.\n",
    "\n",
    "- class: This is the class of the case. It is common to all horses in a race except special races.\n",
    "\n",
    "- num horses: This is the number of horses participated in the race.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99b418f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version = 2.5.0\n"
     ]
    }
   ],
   "source": [
    "#Loading the data and preprocessing it.\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "print(\"tensorflow version = \" + tf.__version__)\n",
    "\n",
    "PATH_TRAINING_DATA = 'training_data/horse_data_train_test.csv'\n",
    "\n",
    "dataset = pd.read_csv(PATH_TRAINING_DATA)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f0ba4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) #use \"fit_transform\" for training data\n",
    "X_test = sc.transform(X_test)       #use \"transform\" for testing data\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical((y_train-1), 14)\n",
    "y_test = tf.keras.utils.to_categorical((y_test-1), 14)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d7e03",
   "metadata": {},
   "source": [
    "<H2> Part 2: Building the Model </H2>\n",
    "\n",
    "We will construct a basic 3-layer model: one input layer, one output layer and one hidden layer.\n",
    "I have tried relu and sigmoid as the activation, and found that sigmoid seems to be a better choice for this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e93c74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new model\n",
    "def build_model():\n",
    "\n",
    "    # Initializing the ANN\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Adding the input layer and the first layer\n",
    "    # We have six features now, and one bias term, so the input layer has a size of 6+1\n",
    "    model.add(tf.keras.layers.Dense(units=7, activation='sigmoid'))\n",
    "    #model.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "\n",
    "    # Adding the input layer and the hidden layer\n",
    "    # We set the size of the hidden layer to be the mean of input and output later, i.e. 10\n",
    "    #model.add(tf.keras.layers.Dense(units=5, activation='sigmoid')) \n",
    "    #model.add(tf.keras.layers.Dense(units=6, activation='sigmoid')) \n",
    "    #model.add(tf.keras.layers.Dense(units=10, activation='sigmoid')) \n",
    "    #model.add(tf.keras.layers.Dense(units=10, activation='relu')) \n",
    "    #model.add(tf.keras.layers.Dense(units=6, activation='sigmoid')) \n",
    "    #model.add(tf.keras.layers.Dense(units=3, activation='sigmoid')) \n",
    "    model.add(tf.keras.layers.Dense(units=12, activation='sigmoid')) \n",
    "    model.add(tf.keras.layers.Dense(units=12, activation='sigmoid')) \n",
    "    model.add(tf.keras.layers.Dense(units=12, activation='sigmoid')) \n",
    "    \n",
    "\n",
    "    # Adding a drop out layer\n",
    "    #model.add(tf.keras.layers.Dropout(0.2))\n",
    "    #model.add(tf.keras.layers.Dropout(0.3))\n",
    "    #model.add(tf.keras.layers.Dropout(0.35277))\n",
    "    #model.add(tf.keras.layers.Dropout(0.17036843627853782))\n",
    "    model.add(tf.keras.layers.Dropout(0.10513604980689638))\n",
    "\n",
    "    #model.add(tf.keras.layers.Dense(units=6, activation='sigmoid')) \n",
    "    #model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    # We have 14 outputs, so the output later has a size of 14\n",
    "    model.add(tf.keras.layers.Dense(units=14, activation='softmax'))\n",
    "\n",
    "    # Compiling the model\n",
    "    #opt = tf.keras.optimizers.Adam(learning_rate=0.03) \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde70ed",
   "metadata": {},
   "source": [
    "<H2> Part 3a: [Optional] Training and saving a new Model </H2>\n",
    "\n",
    "In this section, we would either traing the model from scratch or just load a pre-trained model that is shipped with this Jupyter notebook.\n",
    "\n",
    "- If the training data has been changed or the model has been renewed, go to train a new model in code cell 3a)\n",
    "- If you want to save some time, just skip cell 3a) and load a pre-trained model in code cell 3b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1389b409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "rows in X_train = 693\n",
      "rows in y_train = 693\n",
      "Training model...\n",
      "Epoch 1/5000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:797 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1644 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 14) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21336/2130561540.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#10, #10000, #30000 #50000 #20000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m           callbacks=[tensorboard_callback])\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# save the model for later use\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 764\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3289\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:855 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:838 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:797 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1644 categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4862 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\longi\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1161 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 14) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#This is code cell 3a) that trains a model from scratch and then saves it. Please note that it takes hours to train!\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "%load_ext tensorboard\n",
    "#%reload_ext tensorboard\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "print(\"rows in X_train = \" + str(X_train.shape[0]) )\n",
    "print(\"rows in y_train = \" + str(y_train.shape[0]) )\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          batch_size = 14, \n",
    "          epochs = 5000, #10, #10000, #30000 #50000 #20000\n",
    "          validation_data=(X_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "# save the model for later use\n",
    "print(\"Saving model...\")\n",
    "model.save('saved_model/my_model')\n",
    "\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208fc4c8",
   "metadata": {},
   "source": [
    "<H2> Part 3b: Loading a pre-trained Model </H2>\n",
    "\n",
    "If you have ever run cell 3a), you will load the model that you have trained. Otherwise, you will load a pre-trained model that is shipped with this Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aaa283ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded\n"
     ]
    }
   ],
   "source": [
    "#This is code cell 3b) that loads a pre-trained model. \n",
    "\n",
    "model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "print(\"model is loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae43535",
   "metadata": {},
   "source": [
    "<H2>Part 3c: Model Summary</H2>\n",
    "    \n",
    "Let's take a look at the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "959ec3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 7)                 49        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                96        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 14)                182       \n",
      "=================================================================\n",
      "Total params: 639\n",
      "Trainable params: 639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d7d499",
   "metadata": {},
   "source": [
    "<H2> Part 4: Evaluation </H2>\n",
    "\n",
    "This part calculates the confusion matrix and accuracy_score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cadde48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the weights\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('training_data/horse_data_train_test.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict( X_test )  #y_pred = new_model.predict( sc.fit_transform(X_test) ) \n",
    "y_pred = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18751080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm= [[ 6  0  0  2  1  2  1  1  0  1  0  0  0  0]\n",
      " [ 2  6  0  3  1  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  1  1  2  0  1  1  0  1  1  0  0]\n",
      " [ 3  1  0  3  1  2  0  0  1  1  0  0  1  0]\n",
      " [ 1  0  0  3  3  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  1  2  2  3  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  1  3  2  4  2  1  0  0  0  0  0]\n",
      " [ 0  0  1  4  0  2  1  4  2  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  1  0  2  5  1  1  1  1  0]\n",
      " [ 0  1  0  2  4  0  0  1  0  5  2  0  1  0]\n",
      " [ 0  0  1  2  1  1  0  0  4  1  2  0  1  0]\n",
      " [ 0  1  1  3  1  0  0  0  2  0  3  2  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0 10  0]\n",
      " [ 0  0  0  0  1  0  1  0  0  0  0  0  0  9]]\n",
      "accuracy_score= 0.367816091954023\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, (y_pred+1))\n",
    "print(\"cm=\", cm)\n",
    "print(\"accuracy_score=\", accuracy_score(y_test, (y_pred+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f7776",
   "metadata": {},
   "source": [
    "<H2> Part 5: [Optional] Visualization of the model by Tensorboard </H2>\n",
    "\n",
    "***Note:*** Run this section only if you have run Part3a.\n",
    "\n",
    "By making use of the powerful visual tools given by Tensorboard, we can tune the hyper parameters of the model and visualize the results easily. If the epoch_accuracy is increasing steadily with epoch for the validation set, we could be confident that the model is on track. \n",
    "\n",
    "If we are not satisfy with the performaces shown in the Tensorboard, we can go back to refine the data processing, model building and hyper parameters and check on Tensorboard again iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d43116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling tensorboard...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 13820), started 6 days, 6:25:33 ago. (Use '!kill 13820' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7228e86e375c3ea8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7228e86e375c3ea8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Calling tensorboard...\")\n",
    "\n",
    "#import datetime, os\n",
    "#%load_ext tensorboard\n",
    "#logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "%tensorboard --logdir logs --port=6008 #use a different port if tensorboard fails to load!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01634409",
   "metadata": {},
   "source": [
    "<H2> Part 6: Prediction Checking </H2>\n",
    "\n",
    "In this section, we will try to predict the results of a race on 2021/09/22, and see how accurate the model is by comparing the rediction witht the real results.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cc7b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the csv containing the data of a new race:\n",
    "\n",
    "#CURRENT_RACE_DATA = 'new_data/horse_data_20210926_race8.csv'\n",
    "\n",
    "#CURRENT_RACE_DATA = 'new_data/horse_data_20220101_race5.csv'\n",
    "#CURRENT_RACE_DATA = 'new_data/horse_data_20220105_race3.csv'\n",
    "#CURRENT_RACE_DATA = 'new_data/horse_data_20211205_race6.csv'\n",
    "#CURRENT_RACE_DATA = 'new_data/horse_data_20220109_race4.csv'\n",
    "CURRENT_RACE_DATA = 'new_data/horse_data_20220116_race3.csv'\n",
    "\n",
    "#CURRENT_RACE_DATA = 'new_data/horse_data_20210922_race3.csv'\n",
    "#REAL_FINISHING_POSITIONS = '[ 1  6  4  2 12 10  8  3  7  5 11  9 13 14]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3eeb9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected finishing positions= [ 4  2 12  2 10  5  9  1  5  5  9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "PATH_TRAINING_DATA = 'training_data/horse_data_train_test.csv'\n",
    "\n",
    "#training data\n",
    "dataset = pd.read_csv(PATH_TRAINING_DATA)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "Y = dataset.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0, shuffle=False)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "#live data\n",
    "dataset = pd.read_csv(CURRENT_RACE_DATA)\n",
    "X_live = dataset.iloc[:, :-1].values\n",
    "\n",
    "#use \"transform\" for live data\n",
    "X_live = sc.transform(X_live)\n",
    "\n",
    "#loading pretrained model\n",
    "model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_live)  \n",
    "\n",
    "# Predicting the finishing position\n",
    "y_pred_finishing = np.argmax(y_pred, axis = 1) \n",
    "print(\"Expected finishing positions=\", y_pred_finishing+1)\n",
    "\n",
    "#print(\"The real finishing positions= \" + REAL_FINISHING_POSITIONS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd7ac30",
   "metadata": {},
   "source": [
    "For prediction on your own, you need to create a new csv file that contains the data of a new race in the folder new_data, then run the preditction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30efba64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6fca70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2a136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
